{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate = 0.001):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.Wx = np.random.randn(hidden_size, input_size) * np.sqrt(2 / (input_size + hidden_size))\n",
    "        self.Wh = np.random.randn(hidden_size, hidden_size) * np.sqrt(1 / hidden_size)\n",
    "        self.Wy = np.random.randn(output_size, hidden_size) * np.sqrt(2 / (hidden_size + output_size))\n",
    "        self.bh = np.zeros((hidden_size, 1))\n",
    "        self.by = np.zeros((output_size, 1))\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_prev = np.zeros((self.hidden_size, 1))\n",
    "        self.y_pred, self.h_hist = [], [h_prev]\n",
    "        for t in range(len(x)):\n",
    "            h_t = np.tanh(self.Wx @ x[t].reshape(-1, 1) + self.Wh @ h_prev + self.bh)\n",
    "            y_t = self.sigmoid(self.Wy @ h_t + self.by)\n",
    "            self.y_pred.append(y_t)\n",
    "            self.h_hist.append(h_t)\n",
    "            h_prev = h_t\n",
    "        return self.y_pred\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def tanh_derivative(self, x):\n",
    "        return 1 - x ** 2\n",
    "\n",
    "    def mse(self, y_true, y_pred):\n",
    "        return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "    def mse_derivative(self, y_true, y_pred):\n",
    "        return -2*(y_true - y_pred)\n",
    "\n",
    "    def print_mse(self, X, y):\n",
    "        print(f\"MSE: {self.mse(y.T, np.concatenate(self.forward(X)).flatten())}\")\n",
    "\n",
    "\n",
    "    def backward(self, x, y):\n",
    "        Wy_delta_list = []\n",
    "        by_delta_list = []\n",
    "        Wh_delta_list = []\n",
    "        Wx_delta_list = []\n",
    "        bh_delta_list = []\n",
    "\n",
    "        h_future_delta = np.zeros_like(np.zeros((self.hidden_size, 1)))\n",
    "\n",
    "        for t in reversed(range(len(x))):\n",
    "            y_delta = self.mse_derivative(y[t], self.y_pred[t]) * self.sigmoid_derivative(self.y_pred[t])\n",
    "            h_current_delta = (self.Wy.T @ y_delta) + h_future_delta\n",
    "            h_raw_delta = h_current_delta * self.tanh_derivative(self.h_hist[t])\n",
    "            h_future_delta = self.Wh.T @ h_raw_delta\n",
    "\n",
    "            Wh_delta = h_raw_delta @ self.h_hist[t - 1].T\n",
    "            Wx_delta = h_raw_delta @ x[t].reshape(-1, 1)\n",
    "            Wy_delta = y_delta @ self.h_hist[t].T\n",
    "            bh_delta = h_raw_delta\n",
    "            by_delta = y_delta\n",
    "\n",
    "            Wy_delta_list.append(Wy_delta)\n",
    "            by_delta_list.append(by_delta)\n",
    "            Wh_delta_list.append(Wh_delta)\n",
    "            Wx_delta_list.append(Wx_delta)\n",
    "            bh_delta_list.append(bh_delta)\n",
    "\n",
    "        self.Wy -= np.sum(Wy_delta_list, axis=0) * self.learning_rate\n",
    "        self.by -= np.sum(by_delta_list, axis=0) * self.learning_rate\n",
    "        self.Wh -= np.sum(Wh_delta_list, axis=0) * self.learning_rate\n",
    "        self.Wx -= np.sum(Wx_delta_list, axis=0) * self.learning_rate\n",
    "        self.bh -= np.sum(bh_delta_list, axis=0) * self.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter split_percent defines the ratio of training examples\n",
    "def get_train_test(url, split_percent=0.8):\n",
    "    df = pd.read_csv(url, usecols=[1], engine='python')\n",
    "    data = np.array(df.values.astype('float32'))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data = scaler.fit_transform(data).flatten()\n",
    "    n = len(data)\n",
    "    # Point for splitting data into train and test\n",
    "    split = int(n*split_percent)\n",
    "    train_data = data[range(split)]\n",
    "    test_data = data[split:]\n",
    "    return train_data, test_data, data\n",
    " \n",
    "sunspots_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-sunspots.csv'\n",
    "train_data, test_data, data = get_train_test(sunspots_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size, hidden_size, output_size = 1, 5, 1\n",
    "self = RecurrentNeuralNetwork(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[:-1]  # Input data\n",
    "y = train_data[1:]  # Target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    self.forward(x)\n",
    "    self.backward(x, y)\n",
    "    self.print_mse(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c2396ee008e4910c299ae7134fa9bf09084771bab5830620999247b4a514b46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
