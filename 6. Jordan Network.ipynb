{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhufe\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\zhufe\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\zhufe\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "c:\\Users\\zhufe\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JordanNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.1):\n",
    "        super(JordanNetwork, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.Wx = nn.Parameter(torch.randn(hidden_size, input_size) * torch.sqrt(torch.tensor(2.0 / (input_size + hidden_size))))\n",
    "        self.Wh = nn.Parameter(torch.randn(hidden_size, output_size) * torch.sqrt(torch.tensor(2.0 / (hidden_size + output_size))))\n",
    "        self.Wy = nn.Parameter(torch.randn(output_size, hidden_size) * torch.sqrt(torch.tensor(2.0 / (hidden_size + output_size))))\n",
    "        self.bh = nn.Parameter(torch.zeros(hidden_size, 1))\n",
    "        self.by = nn.Parameter(torch.zeros(output_size, 1))\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_t_1 = torch.zeros(self.output_size, 1)\n",
    "        self.y_pred = []\n",
    "\n",
    "        for t in range(len(x)):\n",
    "            x_t = x[t].view(-1, 1)\n",
    "            h_t = self.tanh(self.Wx @ x_t + self.Wh @ y_t_1 + self.bh)\n",
    "            y_t = self.sigmoid(self.Wy @ h_t + self.by)\n",
    "            self.y_pred.append(y_t)\n",
    "            y_t_1 = y_t\n",
    "        return self.y_pred\n",
    "\n",
    "    def print_mse(self, X, y):\n",
    "        y_pred = torch.cat(self.forward(X)).view(-1)\n",
    "        mse = self.mse_loss(y.view(-1), y_pred)\n",
    "        print(f\"MSE: {mse.item()}\")\n",
    "\n",
    "    def backward(self, x, y):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = self.forward(x)\n",
    "        y_pred_tensor = torch.cat(y_pred).view(-1)\n",
    "        loss = self.mse_loss(y.view(-1), y_pred_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter split_percent defines the ratio of training examples\n",
    "def get_train_test(url, split_percent=0.8):\n",
    "    df = pd.read_csv(url, usecols=[1], engine='python')\n",
    "    data = np.array(df.values.astype('float32'))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data = scaler.fit_transform(data).flatten()\n",
    "    n = len(data)\n",
    "    # Point for splitting data into train and test\n",
    "    split = int(n*split_percent)\n",
    "    train_data = data[range(split)]\n",
    "    test_data = data[split:]\n",
    "    return train_data, test_data, data\n",
    " \n",
    "sunspots_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-sunspots.csv'\n",
    "train_data, test_data, data = get_train_test(sunspots_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size, hidden_size, output_size = 1, 5, 1\n",
    "self = JordanNetwork(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(train_data[:-1])  # Input data\n",
    "y = torch.tensor(train_data[1:])  # Target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.12345875054597855\n",
      "MSE: 0.1143515333533287\n",
      "MSE: 0.10619361698627472\n",
      "MSE: 0.09888488054275513\n",
      "MSE: 0.09233230352401733\n",
      "MSE: 0.08645112067461014\n",
      "MSE: 0.08116500079631805\n",
      "MSE: 0.07640592753887177\n",
      "MSE: 0.07211373001337051\n",
      "MSE: 0.06823528558015823\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    self.forward(x)\n",
    "    self.backward(x, y)\n",
    "    self.print_mse(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c2396ee008e4910c299ae7134fa9bf09084771bab5830620999247b4a514b46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
